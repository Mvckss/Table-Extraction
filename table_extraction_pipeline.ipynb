{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x9CHa7142US5"
   },
   "source": [
    "**Mounted Drive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26159,
     "status": "ok",
     "timestamp": 1735781973664,
     "user": {
      "displayName": "Quan Dang Minh",
      "userId": "08714741247364584629"
     },
     "user_tz": -420
    },
    "id": "IzPwuUKB2Av6",
    "outputId": "281518b8-7153-44cb-963d-6cb15d8193ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yFrug3Tz2B63"
   },
   "source": [
    "**Install Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 1715,
     "status": "ok",
     "timestamp": 1735782054257,
     "user": {
      "displayName": "Quan Dang Minh",
      "userId": "08714741247364584629"
     },
     "user_tz": -420
    },
    "id": "Wb6AJqSI19sV"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import fitz\n",
    "import copy\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json\n",
    "from types import SimpleNamespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 363,
     "status": "ok",
     "timestamp": 1735782070420,
     "user": {
      "displayName": "Quan Dang Minh",
      "userId": "08714741247364584629"
     },
     "user_tz": -420
    },
    "id": "94C5F5nD5KoK"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "folder_path = \"/content/drive/MyDrive/VTS Advance Data Analytic/Project/OCR/user/\"\n",
    "sys.path.append(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "cEnwt7vF41WK"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from doclayout_yolo import YOLOv10\n",
    "from huggingface_hub import snapshot_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "B3Cr_DjQ5hgD"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 3 files:  67%|██████▋   | 2/3 [00:17<00:08,  8.63s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load a pre-trained layout model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m layout_model_dir = \u001b[43msnapshot_download\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mjuliozhao/DocLayout-YOLO-DocStructBench\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/content/drive/MyDrive/VTS Advance Data Analytic/Project/OCR/user/models/DocLayout-YOLO-DocStructBench\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\huggingface_hub\\_snapshot_download.py:332\u001b[39m, in \u001b[36msnapshot_download\u001b[39m\u001b[34m(repo_id, repo_type, revision, cache_dir, local_dir, library_name, library_version, user_agent, proxies, etag_timeout, force_download, token, local_files_only, allow_patterns, ignore_patterns, max_workers, tqdm_class, headers, endpoint, local_dir_use_symlinks, resume_download)\u001b[39m\n\u001b[32m    330\u001b[39m         _inner_hf_hub_download(file)\n\u001b[32m    331\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m332\u001b[39m     \u001b[43mthread_map\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_inner_hf_hub_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfiltered_repo_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtqdm_desc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_workers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# User can use its own tqdm class or the default one from `huggingface_hub.utils`\u001b[39;49;00m\n\u001b[32m    338\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhf_tqdm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m local_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    342\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(os.path.realpath(local_dir))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\tqdm\\contrib\\concurrent.py:69\u001b[39m, in \u001b[36mthread_map\u001b[39m\u001b[34m(fn, *iterables, **tqdm_kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[33;03mEquivalent of `list(map(fn, *iterables))`\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[33;03mdriven by `concurrent.futures.ThreadPoolExecutor`.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     66\u001b[39m \u001b[33;03m    [default: max(32, cpu_count() + 4)].\u001b[39;00m\n\u001b[32m     67\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mconcurrent\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfutures\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ThreadPoolExecutor\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_executor_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mThreadPoolExecutor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43miterables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtqdm_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\tqdm\\contrib\\concurrent.py:51\u001b[39m, in \u001b[36m_executor_map\u001b[39m\u001b[34m(PoolExecutor, fn, *iterables, **tqdm_kwargs)\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ensure_lock(tqdm_class, lock_name=lock_name) \u001b[38;5;28;01mas\u001b[39;00m lk:\n\u001b[32m     48\u001b[39m     \u001b[38;5;66;03m# share lock in case workers are already using `tqdm`\u001b[39;00m\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m PoolExecutor(max_workers=max_workers, initializer=tqdm_class.set_lock,\n\u001b[32m     50\u001b[39m                       initargs=(lk,)) \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43miterables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\tqdm\\std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.1776.0_x64__qbz5n2kfra8p0\\Lib\\concurrent\\futures\\_base.py:619\u001b[39m, in \u001b[36mExecutor.map.<locals>.result_iterator\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[32m    617\u001b[39m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[32m    618\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m619\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_result_or_cancel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    620\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    621\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs.pop(), end_time - time.monotonic())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.1776.0_x64__qbz5n2kfra8p0\\Lib\\concurrent\\futures\\_base.py:317\u001b[39m, in \u001b[36m_result_or_cancel\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    316\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m317\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    318\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    319\u001b[39m         fut.cancel()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.1776.0_x64__qbz5n2kfra8p0\\Lib\\concurrent\\futures\\_base.py:451\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m    449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__get_result()\n\u001b[32m--> \u001b[39m\u001b[32m451\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_condition\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.1776.0_x64__qbz5n2kfra8p0\\Lib\\threading.py:359\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    358\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    360\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    361\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Load a pre-trained layout model\n",
    "layout_model_dir = snapshot_download('juliozhao/DocLayout-YOLO-DocStructBench', local_dir='/content/drive/MyDrive/VTS Advance Data Analytic/Project/OCR/user/models/DocLayout-YOLO-DocStructBench')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IvLz7pPf6ygk"
   },
   "outputs": [],
   "source": [
    "device_id = 0\n",
    "device = torch.device(f\"cuda:{device_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v-YL7W4d5rGP"
   },
   "outputs": [],
   "source": [
    "layout_cfg = dict(layout_model_path=os.path.join(\"/content/drive/MyDrive/VTS Advance Data Analytic/Project/OCR/user/models\", \"DocLayout-YOLO-DocStructBench\", \"doclayout_yolo_docstructbench_imgsz1024.pt\"),\n",
    "                layout_confidence=0.25,\n",
    "                layout_iou_threshold=0.45,\n",
    "                device=device\n",
    "                )\n",
    "layout_cfg = SimpleNamespace(**layout_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zUA3hPjp6kEX"
   },
   "outputs": [],
   "source": [
    "class LayoutParser:\n",
    "    def __init__(self, args):\n",
    "        self.model = YOLOv10(args.layout_model_path)\n",
    "        self.confidence = args.layout_confidence\n",
    "        self.iou_threshold = args.layout_iou_threshold\n",
    "        self.device = args.device\n",
    "        self.id_to_names = {\n",
    "            0: 'title',\n",
    "            1: 'plain text',\n",
    "            2: 'abandon',\n",
    "            3: 'figure',\n",
    "            4: 'figure_caption',\n",
    "            5: 'table',\n",
    "            6: 'table_caption',\n",
    "            7: 'table_footnote',\n",
    "            8: 'isolate_formula',\n",
    "            9: 'formula_caption'\n",
    "        }\n",
    "\n",
    "    def colormap(self, N=256, normalized=False):\n",
    "        \"\"\"\n",
    "        Generate the color map.\n",
    "        Args:\n",
    "            N (int): Number of labels (default is 256).\n",
    "            normalized (bool): If True, return colors normalized to [0, 1]. Otherwise, return [0, 255].\n",
    "        Returns:\n",
    "            np.ndarray: Color map array of shape (N, 3).\n",
    "        \"\"\"\n",
    "        def bitget(byteval, idx):\n",
    "            \"\"\"\n",
    "            Get the bit value at the specified index.\n",
    "            Args:\n",
    "                byteval (int): The byte value.\n",
    "                idx (int): The index of the bit.\n",
    "            Returns:\n",
    "                int: The bit value (0 or 1).\n",
    "            \"\"\"\n",
    "            return ((byteval & (1 << idx)) != 0)\n",
    "\n",
    "        cmap = np.zeros((N, 3), dtype=np.uint8)\n",
    "        for i in range(N):\n",
    "            r = g = b = 0\n",
    "            c = i\n",
    "            for j in range(8):\n",
    "                r = r | (bitget(c, 0) << (7 - j))\n",
    "                g = g | (bitget(c, 1) << (7 - j))\n",
    "                b = b | (bitget(c, 2) << (7 - j))\n",
    "                c = c >> 3\n",
    "            cmap[i] = np.array([r, g, b])\n",
    "\n",
    "        if normalized:\n",
    "            cmap = cmap.astype(np.float32) / 255.0\n",
    "\n",
    "        return cmap\n",
    "\n",
    "    def visualize_bbox(self, image_path, bboxes, classes, scores, alpha=0.3):\n",
    "        \"\"\"\n",
    "        Visualize layout detection results on an image.\n",
    "        Args:\n",
    "            image_path (str): Path to the input image.\n",
    "            bboxes (list): List of bounding boxes, each represented as [x_min, y_min, x_max, y_max].\n",
    "            classes (list): List of class IDs corresponding to the bounding boxes.\n",
    "            id_to_names (dict): Dictionary mapping class IDs to class names.\n",
    "            alpha (float): Transparency factor for the filled color (default is 0.3).\n",
    "        Returns:\n",
    "            np.ndarray: Image with visualized layout detection results.\n",
    "        \"\"\"\n",
    "        # Check if image_path is a PIL.Image.Image object\n",
    "        if isinstance(image_path, Image.Image) or isinstance(image_path, np.ndarray):\n",
    "            image = np.array(image_path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)  # Convert RGB to BGR for OpenCV\n",
    "        else:\n",
    "            image = cv2.imread(image_path)\n",
    "        ori_image = image.copy()\n",
    "        overlay = image.copy()\n",
    "\n",
    "        cmap = self.colormap(N=len(self.id_to_names), normalized=False)\n",
    "\n",
    "        result = []\n",
    "        # Iterate over each bounding box\n",
    "        for i, bbox in enumerate(bboxes):\n",
    "            x_min, y_min, x_max, y_max = map(int, bbox)\n",
    "            class_id = int(classes[i])\n",
    "            class_name = self.id_to_names[class_id]\n",
    "            score = scores[i]\n",
    "            roi_img = ori_image[y_min:y_max, x_min:x_max, :]\n",
    "            # print(roi_img.shape)\n",
    "            result.append({\n",
    "                \"type\": class_name,\n",
    "                \"bbox\": [x_min, y_min, x_max, y_max],\n",
    "                \"score\": score,\n",
    "                \"roi_img\": roi_img\n",
    "            })\n",
    "            text = class_name + f\":{score:.3f}\"\n",
    "\n",
    "            color = tuple(int(c) for c in cmap[class_id])\n",
    "            cv2.rectangle(overlay, (x_min, y_min), (x_max, y_max), color, -1)\n",
    "            cv2.rectangle(image, (x_min, y_min), (x_max, y_max), color, 2)\n",
    "\n",
    "            # Add the class name with a background rectangle\n",
    "            (text_width, text_height), baseline = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.9, 2)\n",
    "            cv2.rectangle(image, (x_min, y_min - text_height - baseline), (x_min + text_width, y_min), color, -1)\n",
    "            cv2.putText(image, text, (x_min, y_min - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2)\n",
    "\n",
    "        # Blend the overlay with the original image\n",
    "        cv2.addWeighted(overlay, alpha, image, 1 - alpha, 0, image)\n",
    "\n",
    "        return result, image\n",
    "\n",
    "    def predict(self, input_img):\n",
    "        det_res = self.model.predict(\n",
    "            input_img,   # Image to predict\n",
    "            imgsz=1024,        # Prediction image size\n",
    "            conf=self.confidence,          # Confidence threshold\n",
    "            device=self.device    # Device to use (e.g., 'cuda:0' or 'cpu')\n",
    "        )[0]\n",
    "        boxes = det_res.__dict__['boxes'].xyxy\n",
    "        classes = det_res.__dict__['boxes'].cls\n",
    "        scores = det_res.__dict__['boxes'].conf\n",
    "\n",
    "        indices = torchvision.ops.nms(boxes=torch.Tensor(boxes), scores=torch.Tensor(scores),iou_threshold=self.iou_threshold)\n",
    "        boxes, scores, classes = boxes[indices], scores[indices], classes[indices]\n",
    "        if len(boxes.shape) == 1:\n",
    "            boxes = np.expand_dims(boxes, 0)\n",
    "            scores = np.expand_dims(scores, 0)\n",
    "            classes = np.expand_dims(classes, 0)\n",
    "\n",
    "        dict_result, vis_result = self.visualize_bbox(input_img, boxes, classes, scores)\n",
    "\n",
    "        return dict_result, vis_result\n",
    "\n",
    "class DocumentExtractor:\n",
    "    def __init__(self, layout_cfg, table_cfg=None, text_cfg=None):\n",
    "        self.layout_cfg = layout_cfg\n",
    "        self.layout_parser = LayoutParser(self.layout_cfg)\n",
    "\n",
    "    def get_layout(self, img):\n",
    "        dict_result, vis_result = self.layout_parser.predict(img)\n",
    "        return dict_result, vis_result\n",
    "\n",
    "    def pdf2img(self, page):\n",
    "        page_scale = 4\n",
    "        mat = fitz.Matrix(page_scale, page_scale)\n",
    "        pm = page.get_pixmap(matrix=mat, alpha=False)\n",
    "        # if pm.width > 2000 or pm.height > 2000:\n",
    "        #     pm = page.get_pixmap(matrix=fitz.Matrix(1, 1), alpha=False)\n",
    "        img = Image.frombytes(\"RGB\", [pm.width, pm.height], pm.samples)\n",
    "        img = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
    "        return img\n",
    "\n",
    "    def __call__(self, filepath):\n",
    "\n",
    "        pages = []\n",
    "        if os.path.basename(filepath)[-3:].lower() in [\"jpg\", \"jpeg\", \"png\"]:\n",
    "            img = cv2.imread(image_file)\n",
    "            img = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
    "            imgs.append(img)\n",
    "\n",
    "        elif os.path.basename(filepath)[-3:].lower() == \"pdf\":\n",
    "            with fitz.open(filepath) as pdf:\n",
    "                for pg in range(0, pdf.page_count):\n",
    "                    page = pdf[pg]\n",
    "                    text_bboxes = []\n",
    "\n",
    "                    for box in page.get_text(\"blocks\"):\n",
    "                        text_bbox = box[:5]\n",
    "                        text_bboxes.append(text_bbox)\n",
    "\n",
    "                    img = self.pdf2img(page)\n",
    "                    pages.append(img)\n",
    "\n",
    "        result = {}\n",
    "        num_pages = len(pages)\n",
    "        document_name = os.path.splitext(os.path.basename(filepath))[0]\n",
    "        result['document_name'] = document_name\n",
    "        result['filepath'] = filepath\n",
    "        result['num_pages'] = num_pages\n",
    "        result['pages'] = []\n",
    "        for page_id in range(num_pages):\n",
    "            page_result = {}\n",
    "            page_result['page_id'] = page_id\n",
    "            img = pages[page_id]\n",
    "            dict_result, vis_result = self.get_layout(img)\n",
    "            page_result['layout'] = dict_result\n",
    "            result['pages'].append(page_result)\n",
    "\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x2Y6kje76-dU"
   },
   "outputs": [],
   "source": [
    "def show_image(img):\n",
    "    plt.figure(figsize=(32, 32), dpi=150)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tOqNexkq6_tu"
   },
   "outputs": [],
   "source": [
    "document_extractor = DocumentExtractor(layout_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sdKr9vFmzWDV"
   },
   "outputs": [],
   "source": [
    "user_name = 'Duc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qRfdiYpr1aTD"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Đường dẫn gốc đến thư mục thực tập\n",
    "base_path = \"/content/drive/MyDrive/VTS Advance Data Analytic/Project/OCR/user/dataset/raw_document\"\n",
    "\n",
    "# Danh sách tên thực tập viên\n",
    "\n",
    "# Hàm thu thập thông tin file từ thư mục\n",
    "def collect_files_from_folder(folder_path):\n",
    "    file_data = []\n",
    "    if os.path.exists(folder_path):  # Kiểm tra thư mục tồn tại\n",
    "        for file in os.listdir(folder_path):\n",
    "            if file.endswith(\".pdf\"):  # Chỉ thu thập file PDF\n",
    "                full_path = os.path.join(folder_path, file)\n",
    "                file_data.append({\n",
    "                    \"File Name\": file,\n",
    "                    \"File Path\": full_path,\n",
    "                    \"Status\": \"Not Processed\",\n",
    "                    \"Table Count\": 0  # Thêm cột Table Count ban đầu là 0\n",
    "                })\n",
    "    return file_data\n",
    "\n",
    "# Hàm cập nhật file log\n",
    "def update_log(user_name, base_path):\n",
    "    # Đường dẫn thư mục và file log\n",
    "    user_path = os.path.join(base_path, user_name)\n",
    "    log_file_path = f\"/content/drive/MyDrive/VTS Advance Data Analytic/Project/OCR/user/file_logs/raw_logs/{user_name}_log.csv\"\n",
    "\n",
    "    # Thu thập danh sách file hiện tại từ thư mục\n",
    "    current_files = collect_files_from_folder(user_path)\n",
    "    current_df = pd.DataFrame(current_files)\n",
    "\n",
    "    # Nếu file log chưa tồn tại, tạo mới\n",
    "    if not os.path.exists(log_file_path):\n",
    "        print(f\"Creating new log file for {user_name}.\")\n",
    "        os.makedirs(os.path.dirname(log_file_path), exist_ok=True)\n",
    "        current_df.to_csv(log_file_path, index=False)\n",
    "        return\n",
    "\n",
    "    # Đọc file log hiện tại\n",
    "    existing_df = pd.read_csv(log_file_path)\n",
    "\n",
    "    # Thêm cột \"Table Count\" nếu chưa tồn tại (đề phòng log cũ chưa có cột này)\n",
    "    if \"Table Count\" not in existing_df.columns:\n",
    "        existing_df[\"Table Count\"] = 0\n",
    "\n",
    "    # So sánh để tìm file mới và file bị xóa\n",
    "    # Tìm file mới (có trong current_df nhưng không có trong existing_df)\n",
    "    new_files = current_df[~current_df[\"File Name\"].isin(existing_df[\"File Name\"])]\n",
    "\n",
    "    # Tìm file bị xóa (có trong existing_df nhưng không còn trong current_df)\n",
    "    removed_files = existing_df[~existing_df[\"File Name\"].isin(current_df[\"File Name\"])]\n",
    "\n",
    "    # Cập nhật log\n",
    "    if not new_files.empty:\n",
    "        print(f\"Adding {len(new_files)} new files to log for {user_name}.\")\n",
    "        existing_df = pd.concat([existing_df, new_files], ignore_index=True)\n",
    "\n",
    "    if not removed_files.empty:\n",
    "        print(f\"Marking {len(removed_files)} files as deleted for {user_name}.\")\n",
    "        existing_df.loc[existing_df[\"File Name\"].isin(removed_files[\"File Name\"]), \"Status\"] = \"Deleted\"\n",
    "\n",
    "    # Lưu lại file log\n",
    "    existing_df.to_csv(log_file_path, index=False)\n",
    "    print(f\"Log for {user_name} updated successfully.\")\n",
    "\n",
    "# Duyệt qua từng thực tập viên và cập nhật log\n",
    "update_log(user_name, base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KqgnzaUV_aPj"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Hàm giả lập document_extractor (thay bằng code thực tế của bạn)\n",
    "# Đường dẫn cơ sở\n",
    "base_path = \"/content/drive/MyDrive/VTS Advance Data Analytic/Project/OCR/user/dataset\"\n",
    "log_path = \"/content/drive/MyDrive/VTS Advance Data Analytic/Project/OCR/user/file_logs/raw_logs\"\n",
    "output_path_base = \"/content/drive/MyDrive/VTS Advance Data Analytic/Project/OCR/user/dataset/table_ocr/image/local\"\n",
    "\n",
    "# Hàm xử lý từng file\n",
    "# Hàm xử lý từng file\n",
    "def process_file(file_name, user_name, log_file_path, output_path):\n",
    "    # Load log file\n",
    "    log_df = pd.read_csv(log_file_path)\n",
    "\n",
    "    # Kiểm tra trạng thái file\n",
    "    file_row = log_df[log_df[\"File Name\"] == file_name]\n",
    "    if not file_row.empty and file_row.iloc[0][\"Status\"] == \"Processed\":\n",
    "        print(f\"Skipping {file_name} as it is already Processed.\")\n",
    "        return\n",
    "\n",
    "    # Thực hiện trích xuất thông tin\n",
    "    # print(f\"Processing {file_name}...\")\n",
    "    file_path = os.path.join(base_path, \"raw_document\", user_name, file_name)\n",
    "    extracted_result = document_extractor(file_path)\n",
    "\n",
    "    # Tạo thư mục đầu ra\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    table_count = 0\n",
    "    for page in extracted_result['pages']:\n",
    "        layout = page['layout']\n",
    "        for box in layout:\n",
    "            if box['type'] == 'table':\n",
    "                table_count += 1\n",
    "                # Lấy ảnh numpy từ box['roi_img']\n",
    "                roi_img = box['roi_img']  # Đây là ảnh numpy array\n",
    "\n",
    "                # Tạo tên file đầu ra\n",
    "                output_file_name = f\"{os.path.splitext(file_name)[0]}_table{table_count}.png\"\n",
    "                output_file_path = os.path.join(output_path, output_file_name)\n",
    "\n",
    "                # Lưu ảnh bằng cv2\n",
    "                if isinstance(roi_img, np.ndarray):\n",
    "                    cv2.imwrite(output_file_path, roi_img)\n",
    "                    print(f\"Saved table image to {output_file_path}\")\n",
    "                else:\n",
    "                    print(f\"Invalid ROI image for {output_file_name}. Skipping...\")\n",
    "\n",
    "    # Cập nhật log file\n",
    "    log_df.loc[log_df[\"File Name\"] == file_name, \"Status\"] = \"Processed\"\n",
    "    log_df.loc[log_df[\"File Name\"] == file_name, \"Table Count\"] += table_count\n",
    "    log_df.to_csv(log_file_path, index=False)\n",
    "\n",
    "    print(f\"Processed {file_name}: {table_count} tables extracted.\")\n",
    "\n",
    "    # print(f\"Processed {file_name}: {table_count} tables extracted.\")\n",
    "\n",
    "# Hàm xử lý tất cả các file của một thực tập viên\n",
    "def process_user_files(user_name):\n",
    "    user_folder = os.path.join(base_path, \"raw_document\", user_name)\n",
    "    log_file_path = os.path.join(log_path, f\"{user_name}_log.csv\")\n",
    "    output_path = os.path.join(output_path_base, user_name)\n",
    "\n",
    "    # Đọc log file\n",
    "    if not os.path.exists(log_file_path):\n",
    "        print(f\"Log file for {user_name} does not exist.\")\n",
    "        return\n",
    "\n",
    "    log_df = pd.read_csv(log_file_path)\n",
    "\n",
    "    # Duyệt qua các file trong thư mục\n",
    "    for file_name in tqdm(os.listdir(user_folder)):\n",
    "        if file_name.endswith(\".pdf\"):\n",
    "            process_file(file_name, user_name, log_file_path, output_path)\n",
    "\n",
    "# Duyệt qua tất cả thực tập viên\n",
    "print(f\"Processing files for {user_name}...\")\n",
    "process_user_files(user_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B282XgXr9SUh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DteAXVcA8-Uz"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
