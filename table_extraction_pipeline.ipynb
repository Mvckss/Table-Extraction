{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x9CHa7142US5"
   },
   "source": [
    "**Mounted Drive**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yFrug3Tz2B63"
   },
   "source": [
    "**Install Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1715,
     "status": "ok",
     "timestamp": 1735782054257,
     "user": {
      "displayName": "Quan Dang Minh",
      "userId": "08714741247364584629"
     },
     "user_tz": -420
    },
    "id": "Wb6AJqSI19sV"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import fitz\n",
    "import copy\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json\n",
    "from types import SimpleNamespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 363,
     "status": "ok",
     "timestamp": 1735782070420,
     "user": {
      "displayName": "Quan Dang Minh",
      "userId": "08714741247364584629"
     },
     "user_tz": -420
    },
    "id": "94C5F5nD5KoK"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "folder_path = \"user/\"\n",
    "sys.path.append(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "cEnwt7vF41WK"
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "# Using local YOLO model for table detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "IvLz7pPf6ygk"
   },
   "outputs": [],
   "source": [
    "device_id = 0\n",
    "device = torch.device(f\"cuda:{device_id}\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "v-YL7W4d5rGP"
   },
   "outputs": [],
   "source": [
    "layout_cfg = dict(layout_model_path=os.path.join(\"user/models\", \"yolov8_table_detection.pt\"),\n",
    "                layout_confidence=0.25,\n",
    "                layout_iou_threshold=0.45,\n",
    "                device=device\n",
    "                )\n",
    "layout_cfg = SimpleNamespace(**layout_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "zUA3hPjp6kEX"
   },
   "outputs": [],
   "source": [
    "class LayoutParser:\n",
    "    def __init__(self, args):\n",
    "        self.model = YOLO(args.layout_model_path)\n",
    "        self.confidence = args.layout_confidence\n",
    "        self.iou_threshold = args.layout_iou_threshold\n",
    "        self.device = args.device\n",
    "        self.id_to_names = {\n",
    "            0: 'title',\n",
    "            1: 'plain text',\n",
    "            2: 'abandon',\n",
    "            3: 'figure',\n",
    "            4: 'figure_caption',\n",
    "            5: 'table',\n",
    "            6: 'table_caption',\n",
    "            7: 'table_footnote',\n",
    "            8: 'isolate_formula',\n",
    "            9: 'formula_caption'\n",
    "        }\n",
    "\n",
    "    def colormap(self, N=256, normalized=False):\n",
    "        \"\"\"\n",
    "        Generate the color map.\n",
    "        Args:\n",
    "            N (int): Number of labels (default is 256).\n",
    "            normalized (bool): If True, return colors normalized to [0, 1]. Otherwise, return [0, 255].\n",
    "        Returns:\n",
    "            np.ndarray: Color map array of shape (N, 3).\n",
    "        \"\"\"\n",
    "        def bitget(byteval, idx):\n",
    "            \"\"\"\n",
    "            Get the bit value at the specified index.\n",
    "            Args:\n",
    "                byteval (int): The byte value.\n",
    "                idx (int): The index of the bit.\n",
    "            Returns:\n",
    "                int: The bit value (0 or 1).\n",
    "            \"\"\"\n",
    "            return ((byteval & (1 << idx)) != 0)\n",
    "\n",
    "        cmap = np.zeros((N, 3), dtype=np.uint8)\n",
    "        for i in range(N):\n",
    "            r = g = b = 0\n",
    "            c = i\n",
    "            for j in range(8):\n",
    "                r = r | (bitget(c, 0) << (7 - j))\n",
    "                g = g | (bitget(c, 1) << (7 - j))\n",
    "                b = b | (bitget(c, 2) << (7 - j))\n",
    "                c = c >> 3\n",
    "            cmap[i] = np.array([r, g, b])\n",
    "\n",
    "        if normalized:\n",
    "            cmap = cmap.astype(np.float32) / 255.0\n",
    "\n",
    "        return cmap\n",
    "\n",
    "    def visualize_bbox(self, image_path, bboxes, classes, scores, alpha=0.3):\n",
    "        \"\"\"\n",
    "        Visualize layout detection results on an image.\n",
    "        Args:\n",
    "            image_path (str): Path to the input image.\n",
    "            bboxes (list): List of bounding boxes, each represented as [x_min, y_min, x_max, y_max].\n",
    "            classes (list): List of class IDs corresponding to the bounding boxes.\n",
    "            id_to_names (dict): Dictionary mapping class IDs to class names.\n",
    "            alpha (float): Transparency factor for the filled color (default is 0.3).\n",
    "        Returns:\n",
    "            np.ndarray: Image with visualized layout detection results.\n",
    "        \"\"\"\n",
    "        # Check if image_path is a PIL.Image.Image object\n",
    "        if isinstance(image_path, Image.Image) or isinstance(image_path, np.ndarray):\n",
    "            image = np.array(image_path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)  # Convert RGB to BGR for OpenCV\n",
    "        else:\n",
    "            image = cv2.imread(image_path)\n",
    "        ori_image = image.copy()\n",
    "        overlay = image.copy()\n",
    "\n",
    "        cmap = self.colormap(N=len(self.id_to_names), normalized=False)\n",
    "\n",
    "        result = []\n",
    "        # Iterate over each bounding box\n",
    "        for i, bbox in enumerate(bboxes):\n",
    "            x_min, y_min, x_max, y_max = map(int, bbox)\n",
    "            class_id = int(classes[i])\n",
    "            class_name = self.id_to_names[class_id]\n",
    "            score = scores[i]\n",
    "            roi_img = ori_image[y_min:y_max, x_min:x_max, :]\n",
    "            # print(roi_img.shape)\n",
    "            result.append({\n",
    "                \"type\": class_name,\n",
    "                \"bbox\": [x_min, y_min, x_max, y_max],\n",
    "                \"score\": score,\n",
    "                \"roi_img\": roi_img\n",
    "            })\n",
    "            text = class_name + f\":{score:.3f}\"\n",
    "\n",
    "            color = tuple(int(c) for c in cmap[class_id])\n",
    "            cv2.rectangle(overlay, (x_min, y_min), (x_max, y_max), color, -1)\n",
    "            cv2.rectangle(image, (x_min, y_min), (x_max, y_max), color, 2)\n",
    "\n",
    "            # Add the class name with a background rectangle\n",
    "            (text_width, text_height), baseline = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.9, 2)\n",
    "            cv2.rectangle(image, (x_min, y_min - text_height - baseline), (x_min + text_width, y_min), color, -1)\n",
    "            cv2.putText(image, text, (x_min, y_min - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2)\n",
    "\n",
    "        # Blend the overlay with the original image\n",
    "        cv2.addWeighted(overlay, alpha, image, 1 - alpha, 0, image)\n",
    "\n",
    "        return result, image\n",
    "\n",
    "    def predict(self, input_img):\n",
    "        det_res = self.model.predict(\n",
    "            input_img,   # Image to predict\n",
    "            imgsz=1024,        # Prediction image size\n",
    "            conf=self.confidence,          # Confidence threshold\n",
    "            device=self.device    # Device to use (e.g., 'cuda:0' or 'cpu')\n",
    "        )[0]\n",
    "        boxes = det_res.boxes.xyxy.cpu().numpy()\n",
    "        classes = det_res.boxes.cls.cpu().numpy()\n",
    "        scores = det_res.boxes.conf.cpu().numpy()\n",
    "\n",
    "        indices = torchvision.ops.nms(boxes=torch.Tensor(boxes), scores=torch.Tensor(scores),iou_threshold=self.iou_threshold)\n",
    "        boxes, scores, classes = boxes[indices], scores[indices], classes[indices]\n",
    "        if len(boxes.shape) == 1:\n",
    "            boxes = np.expand_dims(boxes, 0)\n",
    "            scores = np.expand_dims(scores, 0)\n",
    "            classes = np.expand_dims(classes, 0)\n",
    "\n",
    "        dict_result, vis_result = self.visualize_bbox(input_img, boxes, classes, scores)\n",
    "\n",
    "        return dict_result, vis_result\n",
    "\n",
    "class DocumentExtractor:\n",
    "    def __init__(self, layout_cfg, table_cfg=None, text_cfg=None):\n",
    "        self.layout_cfg = layout_cfg\n",
    "        self.layout_parser = LayoutParser(self.layout_cfg)\n",
    "\n",
    "    def get_layout(self, img):\n",
    "        dict_result, vis_result = self.layout_parser.predict(img)\n",
    "        return dict_result, vis_result\n",
    "\n",
    "    def pdf2img(self, page):\n",
    "        page_scale = 4\n",
    "        mat = fitz.Matrix(page_scale, page_scale)\n",
    "        pm = page.get_pixmap(matrix=mat, alpha=False)\n",
    "        # if pm.width > 2000 or pm.height > 2000:\n",
    "        #     pm = page.get_pixmap(matrix=fitz.Matrix(1, 1), alpha=False)\n",
    "        img = Image.frombytes(\"RGB\", [pm.width, pm.height], pm.samples)\n",
    "        img = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
    "        return img\n",
    "\n",
    "    def __call__(self, filepath):\n",
    "\n",
    "        pages = []\n",
    "        if os.path.basename(filepath)[-3:].lower() in [\"jpg\", \"jpeg\", \"png\"]:\n",
    "            img = cv2.imread(image_file)\n",
    "            img = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
    "            imgs.append(img)\n",
    "\n",
    "        elif os.path.basename(filepath)[-3:].lower() == \"pdf\":\n",
    "            with fitz.open(filepath) as pdf:\n",
    "                for pg in range(0, pdf.page_count):\n",
    "                    page = pdf[pg]\n",
    "                    text_bboxes = []\n",
    "\n",
    "                    for box in page.get_text(\"blocks\"):\n",
    "                        text_bbox = box[:5]\n",
    "                        text_bboxes.append(text_bbox)\n",
    "\n",
    "                    img = self.pdf2img(page)\n",
    "                    pages.append(img)\n",
    "\n",
    "        result = {}\n",
    "        num_pages = len(pages)\n",
    "        document_name = os.path.splitext(os.path.basename(filepath))[0]\n",
    "        result['document_name'] = document_name\n",
    "        result['filepath'] = filepath\n",
    "        result['num_pages'] = num_pages\n",
    "        result['pages'] = []\n",
    "        for page_id in range(num_pages):\n",
    "            page_result = {}\n",
    "            page_result['page_id'] = page_id\n",
    "            img = pages[page_id]\n",
    "            dict_result, vis_result = self.get_layout(img)\n",
    "            page_result['layout'] = dict_result\n",
    "            result['pages'].append(page_result)\n",
    "\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "x2Y6kje76-dU"
   },
   "outputs": [],
   "source": [
    "def show_image(img):\n",
    "    plt.figure(figsize=(32, 32), dpi=150)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "tOqNexkq6_tu"
   },
   "outputs": [],
   "source": [
    "document_extractor = DocumentExtractor(layout_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "sdKr9vFmzWDV"
   },
   "outputs": [],
   "source": [
    "user_name = 'Ant'  # Configure your username here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "qRfdiYpr1aTD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new log file for Ant.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "base_path = \"user/dataset/raw_document\"  # Configure your dataset path here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def collect_files_from_folder(folder_path):\n",
    "    file_data = []\n",
    "    if os.path.exists(folder_path): \n",
    "        for file in os.listdir(folder_path):\n",
    "            if file.endswith(\".pdf\"):  \n",
    "                full_path = os.path.join(folder_path, file)\n",
    "                file_data.append({\n",
    "                    \"File Name\": file,\n",
    "                    \"File Path\": full_path,\n",
    "                    \"Status\": \"Not Processed\",\n",
    "                    \"Table Count\": 0  \n",
    "                })\n",
    "    return file_data\n",
    "\n",
    "\n",
    "def update_log(user_name, base_path):\n",
    "\n",
    "    user_path = os.path.join(base_path, user_name)\n",
    "    log_file_path = f\"user/file_logs/ocr_logs/{user_name}_log.csv\"\n",
    "\n",
    "    current_files = collect_files_from_folder(user_path)\n",
    "    current_df = pd.DataFrame(current_files)\n",
    "\n",
    "\n",
    "    if not os.path.exists(log_file_path):\n",
    "        print(f\"Creating new log file for {user_name}.\")\n",
    "        os.makedirs(os.path.dirname(log_file_path), exist_ok=True)\n",
    "        current_df.to_csv(log_file_path, index=False)\n",
    "        return\n",
    "\n",
    "\n",
    "    existing_df = pd.read_csv(log_file_path)\n",
    "\n",
    "\n",
    "    if \"Table Count\" not in existing_df.columns:\n",
    "        existing_df[\"Table Count\"] = 0\n",
    "\n",
    "\n",
    "    new_files = current_df[~current_df[\"File Name\"].isin(existing_df[\"File Name\"])]\n",
    "\n",
    "\n",
    "    removed_files = existing_df[~existing_df[\"File Name\"].isin(current_df[\"File Name\"])]\n",
    "\n",
    "    if not new_files.empty:\n",
    "        print(f\"Adding {len(new_files)} new files to log for {user_name}.\")\n",
    "        existing_df = pd.concat([existing_df, new_files], ignore_index=True)\n",
    "\n",
    "    if not removed_files.empty:\n",
    "        print(f\"Marking {len(removed_files)} files as deleted for {user_name}.\")\n",
    "        existing_df.loc[existing_df[\"File Name\"].isin(removed_files[\"File Name\"]), \"Status\"] = \"Deleted\"\n",
    "\n",
    "\n",
    "    existing_df.to_csv(log_file_path, index=False)\n",
    "    print(f\"Log for {user_name} updated successfully.\")\n",
    "\n",
    "update_log(user_name, base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "KqgnzaUV_aPj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing files for Ant...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 78\u001b[39m\n\u001b[32m     74\u001b[39m             process_file(file_name, user_name, log_file_path, output_path)\n\u001b[32m     77\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mProcessing files for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m \u001b[43mprocess_user_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 74\u001b[39m, in \u001b[36mprocess_user_files\u001b[39m\u001b[34m(user_name)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m file_name \u001b[38;5;129;01min\u001b[39;00m tqdm(os.listdir(user_folder)):\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m file_name.endswith(\u001b[33m\"\u001b[39m\u001b[33m.pdf\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m         \u001b[43mprocess_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mprocess_file\u001b[39m\u001b[34m(file_name, user_name, log_file_path, output_path)\u001b[39m\n\u001b[32m     22\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     25\u001b[39m file_path = os.path.join(base_path, \u001b[33m\"\u001b[39m\u001b[33mraw_document\u001b[39m\u001b[33m\"\u001b[39m, user_name, file_name)\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m extracted_result = \u001b[43mdocument_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m os.makedirs(output_path, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     31\u001b[39m table_count = \u001b[32m0\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 183\u001b[39m, in \u001b[36mDocumentExtractor.__call__\u001b[39m\u001b[34m(self, filepath)\u001b[39m\n\u001b[32m    181\u001b[39m page_result[\u001b[33m'\u001b[39m\u001b[33mpage_id\u001b[39m\u001b[33m'\u001b[39m] = page_id\n\u001b[32m    182\u001b[39m img = pages[page_id]\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m dict_result, vis_result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_layout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m page_result[\u001b[33m'\u001b[39m\u001b[33mlayout\u001b[39m\u001b[33m'\u001b[39m] = dict_result\n\u001b[32m    185\u001b[39m result[\u001b[33m'\u001b[39m\u001b[33mpages\u001b[39m\u001b[33m'\u001b[39m].append(page_result)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 138\u001b[39m, in \u001b[36mDocumentExtractor.get_layout\u001b[39m\u001b[34m(self, img)\u001b[39m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_layout\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m     dict_result, vis_result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayout_parser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m dict_result, vis_result\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 111\u001b[39m, in \u001b[36mLayoutParser.predict\u001b[39m\u001b[34m(self, input_img)\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_img):\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     det_res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# Image to predict\u001b[39;49;00m\n\u001b[32m    113\u001b[39m \u001b[43m        \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Prediction image size\u001b[39;49;00m\n\u001b[32m    114\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfidence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# Confidence threshold\u001b[39;49;00m\n\u001b[32m    115\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Device to use (e.g., 'cuda:0' or 'cpu')\u001b[39;49;00m\n\u001b[32m    116\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n\u001b[32m    117\u001b[39m     boxes = det_res.boxes.xyxy.cpu().numpy()\n\u001b[32m    118\u001b[39m     classes = det_res.boxes.cls.cpu().numpy()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\ultralytics\\engine\\model.py:555\u001b[39m, in \u001b[36mModel.predict\u001b[39m\u001b[34m(self, source, stream, predictor, **kwargs)\u001b[39m\n\u001b[32m    553\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.predictor, \u001b[33m\"\u001b[39m\u001b[33mset_prompts\u001b[39m\u001b[33m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[32m    554\u001b[39m     \u001b[38;5;28mself\u001b[39m.predictor.set_prompts(prompts)\n\u001b[32m--> \u001b[39m\u001b[32m555\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.predictor.predict_cli(source=source) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m=\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\ultralytics\\engine\\predictor.py:227\u001b[39m, in \u001b[36mBasePredictor.__call__\u001b[39m\u001b[34m(self, source, model, stream, *args, **kwargs)\u001b[39m\n\u001b[32m    225\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stream_inference(source, model, *args, **kwargs)\n\u001b[32m    226\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\utils\\_contextlib.py:38\u001b[39m, in \u001b[36m_wrap_generator.<locals>.generator_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     36\u001b[39m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[32m     37\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m         response = \u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m     41\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     42\u001b[39m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\ultralytics\\engine\\predictor.py:296\u001b[39m, in \u001b[36mBasePredictor.stream_inference\u001b[39m\u001b[34m(self, source, model, *args, **kwargs)\u001b[39m\n\u001b[32m    294\u001b[39m \u001b[38;5;66;03m# Setup model\u001b[39;00m\n\u001b[32m    295\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model:\n\u001b[32m--> \u001b[39m\u001b[32m296\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msetup_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:  \u001b[38;5;66;03m# for thread-safe inference\u001b[39;00m\n\u001b[32m    299\u001b[39m     \u001b[38;5;66;03m# Setup source every time predict is called\u001b[39;00m\n\u001b[32m    300\u001b[39m     \u001b[38;5;28mself\u001b[39m.setup_source(source \u001b[38;5;28;01mif\u001b[39;00m source \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.source)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\ultralytics\\engine\\predictor.py:391\u001b[39m, in \u001b[36mBasePredictor.setup_model\u001b[39m\u001b[34m(self, model, verbose)\u001b[39m\n\u001b[32m    383\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msetup_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, verbose: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m    384\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    385\u001b[39m \u001b[33;03m    Initialize YOLO model with given parameters and set it to evaluation mode.\u001b[39;00m\n\u001b[32m    386\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    389\u001b[39m \u001b[33;03m        verbose (bool): Whether to print verbose output.\u001b[39;00m\n\u001b[32m    390\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m391\u001b[39m     \u001b[38;5;28mself\u001b[39m.model = \u001b[43mAutoBackend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mselect_device\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdnn\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdnn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfp16\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhalf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfuse\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m     \u001b[38;5;28mself\u001b[39m.device = \u001b[38;5;28mself\u001b[39m.model.device  \u001b[38;5;66;03m# update device\u001b[39;00m\n\u001b[32m    402\u001b[39m     \u001b[38;5;28mself\u001b[39m.args.half = \u001b[38;5;28mself\u001b[39m.model.fp16  \u001b[38;5;66;03m# update half\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\utils\\_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\ultralytics\\nn\\autobackend.py:213\u001b[39m, in \u001b[36mAutoBackend.__init__\u001b[39m\u001b[34m(self, weights, device, dnn, data, fp16, fuse, verbose)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m pt:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01multralytics\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtasks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m attempt_load_weights\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m     model = \u001b[43mattempt_load_weights\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfuse\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfuse\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[33m\"\u001b[39m\u001b[33mkpt_shape\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    217\u001b[39m         kpt_shape = model.kpt_shape  \u001b[38;5;66;03m# pose-only\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\ultralytics\\nn\\tasks.py:1503\u001b[39m, in \u001b[36mattempt_load_weights\u001b[39m\u001b[34m(weights, device, inplace, fuse)\u001b[39m\n\u001b[32m   1501\u001b[39m ckpt, w = torch_safe_load(w)  \u001b[38;5;66;03m# load ckpt\u001b[39;00m\n\u001b[32m   1502\u001b[39m args = {**DEFAULT_CFG_DICT, **ckpt[\u001b[33m\"\u001b[39m\u001b[33mtrain_args\u001b[39m\u001b[33m\"\u001b[39m]} \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mtrain_args\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m ckpt \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# combined args\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1503\u001b[39m model = \u001b[43m(\u001b[49m\u001b[43mckpt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mema\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mckpt\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m.float()  \u001b[38;5;66;03m# FP32 model\u001b[39;00m\n\u001b[32m   1505\u001b[39m \u001b[38;5;66;03m# Model compatibility updates\u001b[39;00m\n\u001b[32m   1506\u001b[39m model.args = args  \u001b[38;5;66;03m# attach args to model\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1369\u001b[39m, in \u001b[36mModule.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1366\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1367\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1369\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\ultralytics\\nn\\tasks.py:290\u001b[39m, in \u001b[36mBaseModel._apply\u001b[39m\u001b[34m(self, fn)\u001b[39m\n\u001b[32m    280\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[32m    281\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    282\u001b[39m \u001b[33;03m    Apply a function to all tensors in the model that are not parameters or registered buffers.\u001b[39;00m\n\u001b[32m    283\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    288\u001b[39m \u001b[33;03m        (BaseModel): An updated BaseModel object.\u001b[39;00m\n\u001b[32m    289\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m290\u001b[39m     \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    291\u001b[39m     m = \u001b[38;5;28mself\u001b[39m.model[-\u001b[32m1\u001b[39m]  \u001b[38;5;66;03m# Detect()\u001b[39;00m\n\u001b[32m    292\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    293\u001b[39m         m, Detect\n\u001b[32m    294\u001b[39m     ):  \u001b[38;5;66;03m# includes all Detect subclasses like Segment, Pose, OBB, WorldDetect, YOLOEDetect, YOLOESegment\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\nn\\modules\\module.py:928\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    926\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    927\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m928\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    931\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    932\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    933\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    938\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    939\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\nn\\modules\\module.py:928\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    926\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    927\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m928\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    931\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    932\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    933\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    938\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    939\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\nn\\modules\\module.py:928\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    926\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    927\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m928\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    931\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    932\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    933\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    938\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    939\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\nn\\modules\\module.py:955\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    951\u001b[39m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[32m    952\u001b[39m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[32m    953\u001b[39m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[32m    954\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m955\u001b[39m     param_applied = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    956\u001b[39m p_should_use_set_data = compute_should_use_set_data(param, param_applied)\n\u001b[32m    958\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_subclasses\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfake_tensor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FakeTensor\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1355\u001b[39m, in \u001b[36mModule.to.<locals>.convert\u001b[39m\u001b[34m(t)\u001b[39m\n\u001b[32m   1348\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t.dim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[32m4\u001b[39m, \u001b[32m5\u001b[39m):\n\u001b[32m   1349\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m t.to(\n\u001b[32m   1350\u001b[39m             device,\n\u001b[32m   1351\u001b[39m             dtype \u001b[38;5;28;01mif\u001b[39;00m t.is_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t.is_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1352\u001b[39m             non_blocking,\n\u001b[32m   1353\u001b[39m             memory_format=convert_to_format,\n\u001b[32m   1354\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1355\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1356\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1357\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1358\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1359\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1361\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) == \u001b[33m\"\u001b[39m\u001b[33mCannot copy out of meta tensor; no data!\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\cuda\\__init__.py:403\u001b[39m, in \u001b[36m_lazy_init\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    398\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    399\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    400\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmultiprocessing, you must use the \u001b[39m\u001b[33m'\u001b[39m\u001b[33mspawn\u001b[39m\u001b[33m'\u001b[39m\u001b[33m start method\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    401\u001b[39m     )\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch._C, \u001b[33m\"\u001b[39m\u001b[33m_cuda_getDeviceCount\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m403\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mTorch not compiled with CUDA enabled\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    404\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    405\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[32m    406\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    407\u001b[39m     )\n",
      "\u001b[31mAssertionError\u001b[39m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "base_path = \"user/dataset\"\n",
    "log_path = \"user/file_logs/ocr_logs\"\n",
    "output_path_base = \"user/dataset/table_ocr/image/local\"\n",
    "\n",
    "\n",
    "def process_file(file_name, user_name, log_file_path, output_path):\n",
    "\n",
    "    log_df = pd.read_csv(log_file_path)\n",
    "\n",
    "\n",
    "    file_row = log_df[log_df[\"File Name\"] == file_name]\n",
    "    if not file_row.empty and file_row.iloc[0][\"Status\"] == \"Processed\":\n",
    "        print(f\"Skipping {file_name} as it is already Processed.\")\n",
    "        return\n",
    "\n",
    "\n",
    "    file_path = os.path.join(base_path, \"raw_document\", user_name, file_name)\n",
    "    extracted_result = document_extractor(file_path)\n",
    "\n",
    "\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    table_count = 0\n",
    "    for page in extracted_result['pages']:\n",
    "        layout = page['layout']\n",
    "        for box in layout:\n",
    "            if box['type'] == 'table':\n",
    "                table_count += 1\n",
    "   \n",
    "                roi_img = box['roi_img'] \n",
    "\n",
    "                \n",
    "                output_file_name = f\"{os.path.splitext(file_name)[0]}_table{table_count}.png\"\n",
    "                output_file_path = os.path.join(output_path, output_file_name)\n",
    "\n",
    "                \n",
    "                if isinstance(roi_img, np.ndarray):\n",
    "                    cv2.imwrite(output_file_path, roi_img)\n",
    "                    print(f\"Saved table image to {output_file_path}\")\n",
    "                else:\n",
    "                    print(f\"Invalid ROI image for {output_file_name}. Skipping...\")\n",
    "\n",
    "    \n",
    "    log_df.loc[log_df[\"File Name\"] == file_name, \"Status\"] = \"Processed\"\n",
    "    log_df.loc[log_df[\"File Name\"] == file_name, \"Table Count\"] += table_count\n",
    "    log_df.to_csv(log_file_path, index=False)\n",
    "\n",
    "    print(f\"Processed {file_name}: {table_count} tables extracted.\")\n",
    "\n",
    "\n",
    "def process_user_files(user_name):\n",
    "    user_folder = os.path.join(base_path, \"raw_document\", user_name)\n",
    "    log_file_path = os.path.join(log_path, f\"{user_name}_log.csv\")\n",
    "    output_path = os.path.join(output_path_base, user_name)\n",
    "\n",
    "    \n",
    "    if not os.path.exists(log_file_path):\n",
    "        print(f\"Log file for {user_name} does not exist.\")\n",
    "        return\n",
    "\n",
    "    log_df = pd.read_csv(log_file_path)\n",
    "\n",
    "    \n",
    "    for file_name in tqdm(os.listdir(user_folder)):\n",
    "        if file_name.endswith(\".pdf\"):\n",
    "            process_file(file_name, user_name, log_file_path, output_path)\n",
    "\n",
    "\n",
    "print(f\"Processing files for {user_name}...\")\n",
    "process_user_files(user_name)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
