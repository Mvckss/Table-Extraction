{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x9CHa7142US5"
   },
   "source": [
    "**Mounted Drive**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yFrug3Tz2B63"
   },
   "source": [
    "**Install Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1715,
     "status": "ok",
     "timestamp": 1735782054257,
     "user": {
      "displayName": "Quan Dang Minh",
      "userId": "08714741247364584629"
     },
     "user_tz": -420
    },
    "id": "Wb6AJqSI19sV"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import fitz\n",
    "import copy\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json\n",
    "from types import SimpleNamespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 363,
     "status": "ok",
     "timestamp": 1735782070420,
     "user": {
      "displayName": "Quan Dang Minh",
      "userId": "08714741247364584629"
     },
     "user_tz": -420
    },
    "id": "94C5F5nD5KoK"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "folder_path = \"user/\"\n",
    "sys.path.append(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "cEnwt7vF41WK"
   },
   "outputs": [],
   "source": [
    "from doclayout_yolo import YOLOv10\n",
    "from huggingface_hub import snapshot_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d69ddab6167b4340abe11f92e5fa5895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load a pre-trained layout model\n",
    "layout_model_dir = snapshot_download('juliozhao/DocLayout-YOLO-DocStructBench', local_dir='user/models/DocLayout-YOLO-DocStructBench')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "IvLz7pPf6ygk"
   },
   "outputs": [],
   "source": [
    "device_id = 0\n",
    "device = torch.device(f\"cuda:{device_id}\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "v-YL7W4d5rGP"
   },
   "outputs": [],
   "source": [
    "layout_cfg = dict(layout_model_path=os.path.join(\"user/models\", \"DocLayout-YOLO-DocStructBench\", \"doclayout_yolo_docstructbench_imgsz1024.pt\"),\n",
    "                layout_confidence=0.25,\n",
    "                layout_iou_threshold=0.45,\n",
    "                device=device\n",
    "                )\n",
    "layout_cfg = SimpleNamespace(**layout_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "zUA3hPjp6kEX"
   },
   "outputs": [],
   "source": [
    "class LayoutParser:\n",
    "    def __init__(self, args):\n",
    "        self.model = YOLO(args.layout_model_path)\n",
    "        self.confidence = args.layout_confidence\n",
    "        self.iou_threshold = args.layout_iou_threshold\n",
    "        self.device = args.device\n",
    "        self.id_to_names = {\n",
    "            0: 'title',\n",
    "            1: 'plain text',\n",
    "            2: 'abandon',\n",
    "            3: 'figure',\n",
    "            4: 'figure_caption',\n",
    "            5: 'table',\n",
    "            6: 'table_caption',\n",
    "            7: 'table_footnote',\n",
    "            8: 'isolate_formula',\n",
    "            9: 'formula_caption'\n",
    "        }\n",
    "\n",
    "    def colormap(self, N=256, normalized=False):\n",
    "        \"\"\"\n",
    "        Generate the color map.\n",
    "        Args:\n",
    "            N (int): Number of labels (default is 256).\n",
    "            normalized (bool): If True, return colors normalized to [0, 1]. Otherwise, return [0, 255].\n",
    "        Returns:\n",
    "            np.ndarray: Color map array of shape (N, 3).\n",
    "        \"\"\"\n",
    "        def bitget(byteval, idx):\n",
    "            \"\"\"\n",
    "            Get the bit value at the specified index.\n",
    "            Args:\n",
    "                byteval (int): The byte value.\n",
    "                idx (int): The index of the bit.\n",
    "            Returns:\n",
    "                int: The bit value (0 or 1).\n",
    "            \"\"\"\n",
    "            return ((byteval & (1 << idx)) != 0)\n",
    "\n",
    "        cmap = np.zeros((N, 3), dtype=np.uint8)\n",
    "        for i in range(N):\n",
    "            r = g = b = 0\n",
    "            c = i\n",
    "            for j in range(8):\n",
    "                r = r | (bitget(c, 0) << (7 - j))\n",
    "                g = g | (bitget(c, 1) << (7 - j))\n",
    "                b = b | (bitget(c, 2) << (7 - j))\n",
    "                c = c >> 3\n",
    "            cmap[i] = np.array([r, g, b])\n",
    "\n",
    "        if normalized:\n",
    "            cmap = cmap.astype(np.float32) / 255.0\n",
    "\n",
    "        return cmap\n",
    "\n",
    "    def visualize_bbox(self, image_path, bboxes, classes, scores, alpha=0.3):\n",
    "        \"\"\"\n",
    "        Visualize layout detection results on an image.\n",
    "        Args:\n",
    "            image_path (str): Path to the input image.\n",
    "            bboxes (list): List of bounding boxes, each represented as [x_min, y_min, x_max, y_max].\n",
    "            classes (list): List of class IDs corresponding to the bounding boxes.\n",
    "            id_to_names (dict): Dictionary mapping class IDs to class names.\n",
    "            alpha (float): Transparency factor for the filled color (default is 0.3).\n",
    "        Returns:\n",
    "            np.ndarray: Image with visualized layout detection results.\n",
    "        \"\"\"\n",
    "        # Check if image_path is a PIL.Image.Image object\n",
    "        if isinstance(image_path, Image.Image) or isinstance(image_path, np.ndarray):\n",
    "            image = np.array(image_path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)  # Convert RGB to BGR for OpenCV\n",
    "        else:\n",
    "            image = cv2.imread(image_path)\n",
    "        ori_image = image.copy()\n",
    "        overlay = image.copy()\n",
    "\n",
    "        cmap = self.colormap(N=len(self.id_to_names), normalized=False)\n",
    "\n",
    "        result = []\n",
    "        # Iterate over each bounding box\n",
    "        for i, bbox in enumerate(bboxes):\n",
    "            x_min, y_min, x_max, y_max = map(int, bbox)\n",
    "            class_id = int(classes[i])\n",
    "            class_name = self.id_to_names[class_id]\n",
    "            score = scores[i]\n",
    "            roi_img = ori_image[y_min:y_max, x_min:x_max, :]\n",
    "            # print(roi_img.shape)\n",
    "            result.append({\n",
    "                \"type\": class_name,\n",
    "                \"bbox\": [x_min, y_min, x_max, y_max],\n",
    "                \"score\": score,\n",
    "                \"roi_img\": roi_img\n",
    "            })\n",
    "            text = class_name + f\":{score:.3f}\"\n",
    "\n",
    "            color = tuple(int(c) for c in cmap[class_id])\n",
    "            cv2.rectangle(overlay, (x_min, y_min), (x_max, y_max), color, -1)\n",
    "            cv2.rectangle(image, (x_min, y_min), (x_max, y_max), color, 2)\n",
    "\n",
    "            # Add the class name with a background rectangle\n",
    "            (text_width, text_height), baseline = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.9, 2)\n",
    "            cv2.rectangle(image, (x_min, y_min - text_height - baseline), (x_min + text_width, y_min), color, -1)\n",
    "            cv2.putText(image, text, (x_min, y_min - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2)\n",
    "\n",
    "        # Blend the overlay with the original image\n",
    "        cv2.addWeighted(overlay, alpha, image, 1 - alpha, 0, image)\n",
    "\n",
    "        return result, image\n",
    "\n",
    "    def predict(self, input_img):\n",
    "        det_res = self.model.predict(\n",
    "            input_img,   # Image to predict\n",
    "            imgsz=1024,        # Prediction image size\n",
    "            conf=self.confidence,          # Confidence threshold\n",
    "            device=self.device    # Device to use (e.g., 'cuda:0' or 'cpu')\n",
    "        )[0]\n",
    "        boxes = det_res.boxes.xyxy.cpu().numpy()\n",
    "        classes = det_res.boxes.cls.cpu().numpy()\n",
    "        scores = det_res.boxes.conf.cpu().numpy()\n",
    "\n",
    "        indices = torchvision.ops.nms(boxes=torch.Tensor(boxes), scores=torch.Tensor(scores),iou_threshold=self.iou_threshold)\n",
    "        boxes, scores, classes = boxes[indices], scores[indices], classes[indices]\n",
    "        if len(boxes.shape) == 1:\n",
    "            boxes = np.expand_dims(boxes, 0)\n",
    "            scores = np.expand_dims(scores, 0)\n",
    "            classes = np.expand_dims(classes, 0)\n",
    "\n",
    "        dict_result, vis_result = self.visualize_bbox(input_img, boxes, classes, scores)\n",
    "\n",
    "        return dict_result, vis_result\n",
    "\n",
    "class DocumentExtractor:\n",
    "    def __init__(self, layout_cfg, table_cfg=None, text_cfg=None):\n",
    "        self.layout_cfg = layout_cfg\n",
    "        self.layout_parser = LayoutParser(self.layout_cfg)\n",
    "\n",
    "    def get_layout(self, img):\n",
    "        dict_result, vis_result = self.layout_parser.predict(img)\n",
    "        return dict_result, vis_result\n",
    "\n",
    "    def pdf2img(self, page):\n",
    "        page_scale = 4\n",
    "        mat = fitz.Matrix(page_scale, page_scale)\n",
    "        pm = page.get_pixmap(matrix=mat, alpha=False)\n",
    "        # if pm.width > 2000 or pm.height > 2000:\n",
    "        #     pm = page.get_pixmap(matrix=fitz.Matrix(1, 1), alpha=False)\n",
    "        img = Image.frombytes(\"RGB\", [pm.width, pm.height], pm.samples)\n",
    "        img = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
    "        return img\n",
    "\n",
    "    def __call__(self, filepath):\n",
    "\n",
    "        pages = []\n",
    "        if os.path.basename(filepath)[-3:].lower() in [\"jpg\", \"jpeg\", \"png\"]:\n",
    "            img = cv2.imread(image_file)\n",
    "            img = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
    "            imgs.append(img)\n",
    "\n",
    "        elif os.path.basename(filepath)[-3:].lower() == \"pdf\":\n",
    "            with fitz.open(filepath) as pdf:\n",
    "                for pg in range(0, pdf.page_count):\n",
    "                    page = pdf[pg]\n",
    "                    text_bboxes = []\n",
    "\n",
    "                    for box in page.get_text(\"blocks\"):\n",
    "                        text_bbox = box[:5]\n",
    "                        text_bboxes.append(text_bbox)\n",
    "\n",
    "                    img = self.pdf2img(page)\n",
    "                    pages.append(img)\n",
    "\n",
    "        result = {}\n",
    "        num_pages = len(pages)\n",
    "        document_name = os.path.splitext(os.path.basename(filepath))[0]\n",
    "        result['document_name'] = document_name\n",
    "        result['filepath'] = filepath\n",
    "        result['num_pages'] = num_pages\n",
    "        result['pages'] = []\n",
    "        for page_id in range(num_pages):\n",
    "            page_result = {}\n",
    "            page_result['page_id'] = page_id\n",
    "            img = pages[page_id]\n",
    "            dict_result, vis_result = self.get_layout(img)\n",
    "            page_result['layout'] = dict_result\n",
    "            result['pages'].append(page_result)\n",
    "\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "x2Y6kje76-dU"
   },
   "outputs": [],
   "source": [
    "def show_image(img):\n",
    "    plt.figure(figsize=(32, 32), dpi=150)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "tOqNexkq6_tu"
   },
   "outputs": [],
   "source": [
    "document_extractor = DocumentExtractor(layout_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "sdKr9vFmzWDV"
   },
   "outputs": [],
   "source": [
    "user_name = 'Ant'  # Configure your username here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "qRfdiYpr1aTD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log for Ant updated successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "base_path = \"user/dataset/raw_document\"  # Configure your dataset path here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def collect_files_from_folder(folder_path):\n",
    "    file_data = []\n",
    "    if os.path.exists(folder_path): \n",
    "        for file in os.listdir(folder_path):\n",
    "            if file.endswith(\".pdf\"):  \n",
    "                full_path = os.path.join(folder_path, file)\n",
    "                file_data.append({\n",
    "                    \"File Name\": file,\n",
    "                    \"File Path\": full_path,\n",
    "                    \"Status\": \"Not Processed\",\n",
    "                    \"Table Count\": 0  \n",
    "                })\n",
    "    return file_data\n",
    "\n",
    "\n",
    "def update_log(user_name, base_path):\n",
    "\n",
    "    user_path = os.path.join(base_path, user_name)\n",
    "    log_file_path = f\"user/file_logs/ocr_logs/{user_name}_log.csv\"\n",
    "\n",
    "    current_files = collect_files_from_folder(user_path)\n",
    "    current_df = pd.DataFrame(current_files)\n",
    "\n",
    "\n",
    "    if not os.path.exists(log_file_path):\n",
    "        print(f\"Creating new log file for {user_name}.\")\n",
    "        os.makedirs(os.path.dirname(log_file_path), exist_ok=True)\n",
    "        current_df.to_csv(log_file_path, index=False)\n",
    "        return\n",
    "\n",
    "\n",
    "    existing_df = pd.read_csv(log_file_path)\n",
    "\n",
    "\n",
    "    if \"Table Count\" not in existing_df.columns:\n",
    "        existing_df[\"Table Count\"] = 0\n",
    "\n",
    "\n",
    "    new_files = current_df[~current_df[\"File Name\"].isin(existing_df[\"File Name\"])]\n",
    "\n",
    "\n",
    "    removed_files = existing_df[~existing_df[\"File Name\"].isin(current_df[\"File Name\"])]\n",
    "\n",
    "    if not new_files.empty:\n",
    "        print(f\"Adding {len(new_files)} new files to log for {user_name}.\")\n",
    "        existing_df = pd.concat([existing_df, new_files], ignore_index=True)\n",
    "\n",
    "    if not removed_files.empty:\n",
    "        print(f\"Marking {len(removed_files)} files as deleted for {user_name}.\")\n",
    "        existing_df.loc[existing_df[\"File Name\"].isin(removed_files[\"File Name\"]), \"Status\"] = \"Deleted\"\n",
    "\n",
    "\n",
    "    existing_df.to_csv(log_file_path, index=False)\n",
    "    print(f\"Log for {user_name} updated successfully.\")\n",
    "\n",
    "update_log(user_name, base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "KqgnzaUV_aPj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing files for Ant...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 495.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Grade 12 Transcript.pdf as it is already Processed.\n",
      "Skipping Xác nhận số dư sổ tiết kiệm.pdf as it is already Processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "base_path = \"user/dataset\"\n",
    "log_path = \"user/file_logs/ocr_logs\"\n",
    "output_path_base = \"user/dataset/table_ocr/image/local\"\n",
    "\n",
    "\n",
    "def process_file(file_name, user_name, log_file_path, output_path):\n",
    "\n",
    "    log_df = pd.read_csv(log_file_path)\n",
    "\n",
    "\n",
    "    file_row = log_df[log_df[\"File Name\"] == file_name]\n",
    "    if not file_row.empty and file_row.iloc[0][\"Status\"] == \"Processed\":\n",
    "        print(f\"Skipping {file_name} as it is already Processed.\")\n",
    "        return\n",
    "\n",
    "\n",
    "    file_path = os.path.join(base_path, \"raw_document\", user_name, file_name)\n",
    "    extracted_result = document_extractor(file_path)\n",
    "\n",
    "\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    table_count = 0\n",
    "    for page in extracted_result['pages']:\n",
    "        layout = page['layout']\n",
    "        for box in layout:\n",
    "            if box['type'] == 'table':\n",
    "                table_count += 1\n",
    "   \n",
    "                roi_img = box['roi_img'] \n",
    "\n",
    "                \n",
    "                output_file_name = f\"{os.path.splitext(file_name)[0]}_table{table_count}.png\"\n",
    "                output_file_path = os.path.join(output_path, output_file_name)\n",
    "\n",
    "                \n",
    "                if isinstance(roi_img, np.ndarray):\n",
    "                    cv2.imwrite(output_file_path, roi_img)\n",
    "                    print(f\"Saved table image to {output_file_path}\")\n",
    "                else:\n",
    "                    print(f\"Invalid ROI image for {output_file_name}. Skipping...\")\n",
    "\n",
    "    \n",
    "    log_df.loc[log_df[\"File Name\"] == file_name, \"Status\"] = \"Processed\"\n",
    "    log_df.loc[log_df[\"File Name\"] == file_name, \"Table Count\"] += table_count\n",
    "    log_df.to_csv(log_file_path, index=False)\n",
    "\n",
    "    print(f\"Processed {file_name}: {table_count} tables extracted.\")\n",
    "\n",
    "\n",
    "def process_user_files(user_name):\n",
    "    user_folder = os.path.join(base_path, \"raw_document\", user_name)\n",
    "    log_file_path = os.path.join(log_path, f\"{user_name}_log.csv\")\n",
    "    output_path = os.path.join(output_path_base, user_name)\n",
    "\n",
    "    \n",
    "    if not os.path.exists(log_file_path):\n",
    "        print(f\"Log file for {user_name} does not exist.\")\n",
    "        return\n",
    "\n",
    "    log_df = pd.read_csv(log_file_path)\n",
    "\n",
    "    \n",
    "    for file_name in tqdm(os.listdir(user_folder)):\n",
    "        if file_name.endswith(\".pdf\"):\n",
    "            process_file(file_name, user_name, log_file_path, output_path)\n",
    "\n",
    "\n",
    "print(f\"Processing files for {user_name}...\")\n",
    "process_user_files(user_name)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
